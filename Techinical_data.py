"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   INSTITUTIONAL MARKET INTELLIGENCE ENGINE                       â•‘
â•‘   Module: institutional_edge.py                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   Covers ALL 8 Institutional Dimensions:                         â•‘
â•‘   1. DOM â€” Real Order Book (5-level Bid/Ask Depth)               â•‘
â•‘   2. Order Flow â€” Delta, Imbalance, Absorption                   â•‘
â•‘   3. Institutional Positioning â€” Block trades, FII proxy         â•‘
â•‘   4. Macro Clock â€” Market session time behavior                  â•‘
â•‘   5. Liquidity Engineering â€” Stop hunts, equal highs/lows        â•‘
â•‘   6. Options OI â€” Max Pain, PCR, Gamma zones                     â•‘
â•‘   7. Time-Based Behavior â€” Session analysis (9:15/midday/close)  â•‘
â•‘   8. Psychology Gauge â€” Fear/Greed, FOMO, Trap detection         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   Import into watchlist_intelligence.py OR run standalone        â•‘
â•‘   Usage: python institutional_edge.py --stock DIXON              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  What Upstox API CAN provide (used here):
  âœ… 5-level Bid/Ask DOM (depth) from full market quote
  âœ… Total buy qty vs sell qty â†’ order flow delta
  âœ… Volume spikes â†’ block deal detection
  âœ… 1-minute candles â†’ intraday session analysis
  âœ… Options chain (PCR, OI, Max Pain) for NSE_INDEX linked stocks
  âœ… OHLC for liquidity zone mapping

  What Upstox API CANNOT provide (hard limits â€” explained):
  âŒ True tick-by-tick footprint (who hit bid / lifted ask)
  âŒ Dark pool / block deal exact counterparties
  âŒ Real-time FII/DII flows (NSE publishes EOD only)
  âŒ Iceberg order detection (exchange hides these)
  âŒ Gamma exposure (requires options MM book data)
"""

import argparse
import requests
import sys
from datetime import datetime, timedelta, time as dtime

try:
    import pandas as pd
    import numpy as np
    HAS_PANDAS = True
except ImportError:
    HAS_PANDAS = False

try:
    from tabulate import tabulate
    HAS_TABULATE = True
except ImportError:
    HAS_TABULATE = False

# â”€â”€ Copy your token here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ACCESS_TOKEN = "eyJ0eXAiOiJKV1QiLCJrZXlfaWQiOiJza192MS4wIiwiYWxnIjoiSFMyNTYifQ.eyJzdWIiOiIyQkNCNzQiLCJqdGkiOiI2OTlkMjQ5OTA0NTQxZTc2ZWRkMzMzODMiLCJpc011bHRpQ2xpZW50IjpmYWxzZSwiaXNQbHVzUGxhbiI6dHJ1ZSwiaWF0IjoxNzcxOTA2MjAxLCJpc3MiOiJ1ZGFwaS1nYXRld2F5LXNlcnZpY2UiLCJleHAiOjE3NzE5NzA0MDB9.k8M6pdpFGofqQUBiyDa0teyS3LqPq9afMSQ2pO0ZWss"

BASE_URL = "https://api.upstox.com/v2"
DIVIDER  = "â•" * 68
THIN     = "â”€" * 68

# Watchlist (same as watchlist_intelligence.py)
WATCHLIST = {
    "PAGEIND":   {"key": "NSE_EQ|INE761H01022", "name": "Page Industries",           "fo_key": None},
    "SHREECEM":  {"key": "NSE_EQ|INE070A01015", "name": "Shree Cement",               "fo_key": None},
    "MARUTI":    {"key": "NSE_EQ|INE585B01010", "name": "Maruti Suzuki",              "fo_key": "NSE_FO"},
    "SOLARINDS": {"key": "NSE_EQ|INE03D201019", "name": "Solar Industries",           "fo_key": None},
    "PAYTM":     {"key": "NSE_EQ|INE982J01020", "name": "Paytm",                      "fo_key": None},
    "BOSCHLTD":  {"key": "NSE_EQ|INE323A01026", "name": "Bosch Ltd",                  "fo_key": None},
    "DIXON":     {"key": "NSE_EQ|INE935N01012", "name": "Dixon Technologies",         "fo_key": None},
    "ULTRACEMCO":{"key": "NSE_EQ|INE481G01011", "name": "UltraTech Cement",           "fo_key": "NSE_FO"},
    "JIOFIN":    {"key": "NSE_EQ|INE758T01015", "name": "Jio Financial Services",     "fo_key": None},
    "OFSS":      {"key": "NSE_EQ|INE881D01027", "name": "Oracle Financial Services",  "fo_key": None},
    "POLYCAB":   {"key": "NSE_EQ|INE455K01017", "name": "Polycab India",              "fo_key": None},
    "ABB":       {"key": "NSE_EQ|INE117A01022", "name": "ABB India",                  "fo_key": None},
    "DIVISLAB":  {"key": "NSE_EQ|INE361B01024", "name": "Divi's Laboratories",        "fo_key": "NSE_FO"},
}

# NIFTY 50 instrument key for index options context
NIFTY_KEY = "NSE_INDEX|Nifty 50"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  DISPLAY HELPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def clr(t, c): return f"\033[{c}m{t}\033[0m"
def green(t):  return clr(t, "92")
def red(t):    return clr(t, "91")
def yellow(t): return clr(t, "93")
def cyan(t):   return clr(t, "96")
def bold(t):   return clr(t, "1")
def dim(t):    return clr(t, "2")
def magenta(t):return clr(t, "95")

def section(title):
    print(f"\n{THIN}")
    print(f"  {bold(cyan(title))}")
    print(THIN)

def tbl(rows, headers):
    if HAS_TABULATE:
        print(tabulate(rows, headers=headers, tablefmt="rounded_outline"))
    else:
        widths = [max(len(str(r[i])) for r in ([headers] + list(rows))) for i in range(len(headers))]
        fmt = "  ".join(f"{{:<{w}}}" for w in widths)
        print(fmt.format(*headers))
        print("  ".join("-"*w for w in widths))
        for r in rows:
            print(fmt.format(*[str(x) for x in r]))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  API HELPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def hdrs(token):
    return {"Authorization": f"Bearer {token}", "Accept": "application/json"}

def api_get(token, endpoint, params=None):
    try:
        r = requests.get(f"{BASE_URL}{endpoint}", headers=hdrs(token), params=params, timeout=12)
        r.raise_for_status()
        return r.json()
    except requests.exceptions.HTTPError:
        print(red(f"  âŒ HTTP {r.status_code}: {r.text[:100]}"))
        return None
    except Exception as e:
        print(red(f"  âŒ Error: {e}"))
        return None

def fetch_full_quote(token, instrument_key):
    """Full quote includes DOM depth (5 bid/ask levels)."""
    data = api_get(token, "/market-quote/quotes", {"instrument_key": instrument_key})
    if data and data.get("status") == "success":
        d = data.get("data", {})
        k = list(d.keys())[0] if d else None
        return d.get(k, {}) if k else {}
    return {}

def fetch_intraday_candles(token, instrument_key, interval="1minute", days=1):
    """1-minute candles for intraday session analysis."""
    to_dt = datetime.today()
    fr_dt = to_dt - timedelta(days=days + 3)
    endpoint = f"/historical-candle/intraday/{instrument_key}/{interval}"
    data = api_get(token, endpoint)
    if not data or data.get("status") != "success":
        # fallback to historical
        to_str = to_dt.strftime("%Y-%m-%d")
        fr_str = fr_dt.strftime("%Y-%m-%d")
        endpoint2 = f"/historical-candle/{instrument_key}/{interval}/{to_str}/{fr_str}"
        data = api_get(token, endpoint2)
    if not data or data.get("status") != "success":
        return None
    candles = data.get("data", {}).get("candles", [])
    if not candles or not HAS_PANDAS:
        return None
    df = pd.DataFrame(candles, columns=["ts", "open", "high", "low", "close", "volume", "oi"])
    df["ts"] = pd.to_datetime(df["ts"])
    df = df.sort_values("ts").reset_index(drop=True)
    return df

def fetch_daily_candles(token, instrument_key, days=60):
    to_dt  = datetime.today()
    fr_dt  = to_dt - timedelta(days=days + 20)
    to_str = to_dt.strftime("%Y-%m-%d")
    fr_str = fr_dt.strftime("%Y-%m-%d")
    endpoint = f"/historical-candle/{instrument_key}/day/{to_str}/{fr_str}"
    data = api_get(token, endpoint)
    if not data or data.get("status") != "success":
        return None
    candles = data.get("data", {}).get("candles", [])
    if not candles or not HAS_PANDAS:
        return None
    df = pd.DataFrame(candles, columns=["ts", "open", "high", "low", "close", "volume", "oi"])
    df["ts"] = pd.to_datetime(df["ts"])
    return df.sort_values("ts").reset_index(drop=True)

def fetch_option_chain(token, index_key, expiry_date):
    """Fetch full option chain (PCR, OI, Max Pain)."""
    data = api_get(token, "/option/chain", {
        "instrument_key": index_key,
        "expiry_date": expiry_date
    })
    if data and data.get("status") == "success":
        return data.get("data", [])
    return []

def fetch_option_expiries(token, index_key):
    """Get available expiry dates."""
    data = api_get(token, "/option/contract", {"instrument_key": index_key})
    if data and data.get("status") == "success":
        contracts = data.get("data", [])
        expiries = sorted(set(c.get("expiry") for c in contracts if c.get("expiry")))
        return expiries
    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  1. DOM â€” DEPTH OF MARKET ANALYSIS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_dom(quote: dict):
    """
    Real Order Book Analysis.
    Upstox provides 5-level DOM via full market quote.
    We compute:
    - Bid/Ask imbalance
    - Wall detection (large stacked orders)
    - Absorption signal (price not moving despite large orders)
    """
    section("ğŸ›ï¸  [1] DOM â€” DEPTH OF MARKET (Order Book)")

    depth = quote.get("depth", {})
    bids  = depth.get("buy",  [])
    asks  = depth.get("sell", [])

    ltp = quote.get("last_price", 0)

    if not bids and not asks:
        print(red("  âŒ DOM data not available (market may be closed or no depth returned)."))
        print(dim("  ğŸ’¡ DOM is only meaningful during live market hours (9:15 AM â€“ 3:30 PM IST)."))
        return

    print(f"\n  {'BIDS (Buy Side)':^35}  {'ASKS (Sell Side)':^35}")
    print(f"  {'â”€'*35}  {'â”€'*35}")
    print(f"  {'Orders':>8}  {'Qty':>12}  {'Price':>10}  {'Price':>10}  {'Qty':>12}  {'Orders':>8}")
    print(f"  {'â”€'*35}  {'â”€'*35}")

    total_bid_qty = 0
    total_ask_qty = 0
    bid_wall = None
    ask_wall = None
    BID_WALL_THRESHOLD = 50000  # Shares â€” adjust for stock liquidity

    for i in range(max(len(bids), len(asks))):
        b = bids[i] if i < len(bids) else {"quantity": 0, "price": 0, "orders": 0}
        a = asks[i] if i < len(asks) else {"quantity": 0, "price": 0, "orders": 0}

        b_qty = b.get("quantity", 0)
        a_qty = a.get("quantity", 0)
        total_bid_qty += b_qty
        total_ask_qty += a_qty

        b_flag = " âš¡WALL" if b_qty >= BID_WALL_THRESHOLD else ""
        a_flag = " âš¡WALL" if a_qty >= BID_WALL_THRESHOLD else ""
        if b_qty >= BID_WALL_THRESHOLD: bid_wall = b.get("price", 0)
        if a_qty >= BID_WALL_THRESHOLD: ask_wall = a.get("price", 0)

        b_str = green(f"{b['orders']:>8}  {b_qty:>12,}  â‚¹{b['price']:>9.2f}")
        a_str = red(f"â‚¹{a['price']:>9.2f}  {a_qty:>12,}  {a['orders']:>8}")

        print(f"  {b_str}  {a_str}{a_flag}")

    print(f"  {'â”€'*35}  {'â”€'*35}")

    # Bid/Ask imbalance
    total = total_bid_qty + total_ask_qty
    bid_pct = (total_bid_qty / total * 100) if total > 0 else 50
    ask_pct = 100 - bid_pct

    print(f"\n  ğŸ“Š ORDER FLOW IMBALANCE:")
    bar_len = 40
    bid_bar = int(bid_pct / 100 * bar_len)
    ask_bar = bar_len - bid_bar
    bar = green("â–ˆ" * bid_bar) + red("â–ˆ" * ask_bar)
    print(f"  BID [{bar}] ASK")
    print(f"  {green(f'Buy: {total_bid_qty:,} ({bid_pct:.1f}%)')}  {red(f'Sell: {total_ask_qty:,} ({ask_pct:.1f}%)')}")

    print(f"\n  ğŸ“Œ INTERPRETATION:")
    rows = []
    if bid_pct > 60:
        rows.append([green("DOM BIAS"),       green("BUY SIDE HEAVY"),   f"{bid_pct:.1f}% bid stacked â€” strong buying interest"])
    elif ask_pct > 60:
        rows.append([red("DOM BIAS"),         red("SELL SIDE HEAVY"),    f"{ask_pct:.1f}% ask stacked â€” distribution/selling pressure"])
    else:
        rows.append([yellow("DOM BIAS"),      yellow("BALANCED"),         "No dominant side â€” wait for absorption to resolve"])

    if bid_wall:
        rows.append([green("BID WALL"),       green(f"â‚¹{bid_wall:.2f}"), "Large buy order â€” acts as strong support floor"])
    if ask_wall:
        rows.append([red("ASK WALL"),         red(f"â‚¹{ask_wall:.2f}"),  "Large sell order â€” acts as resistance ceiling"])

    # Iceberg detection heuristic
    # If price is near bid wall but wall is NOT shrinking = iceberg (hidden refresh)
    rows.append([dim("Iceberg Orders"),   dim("âš ï¸  UNDETECTABLE"),  "Exchanges hide refreshed orders â€” monitor via DOM changes over time"])
    rows.append([dim("Hidden Liquidity"), dim("âš ï¸  UNDETECTABLE"),  "Dark pools, off-market blocks not visible in DOM"])

    tbl(rows, ["Signal", "Reading", "Interpretation"])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  2. ORDER FLOW DELTA â€” CUMULATIVE DELTA PROXY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_order_flow(quote: dict, df_intraday):
    """
    True order flow requires tick data (who hit bid vs lifted ask).
    Upstox REST API gives candles only â€” no tick data.
    We compute the best available proxies:
    - Candle delta (close vs open direction Ã— volume)
    - Cumulative delta over session
    - Bid/Ask absorption from DOM
    """
    section("âš¡ [2] ORDER FLOW â€” CUMULATIVE DELTA & BID/ASK ABSORPTION")

    # From DOM
    tbq = quote.get("total_buy_quantity",  0) or 0
    tsq = quote.get("total_sell_quantity", 0) or 0
    ltp = quote.get("last_price", 0) or 0
    avg = quote.get("average_price", 0) or 0

    total = tbq + tsq
    if total > 0:
        buy_pct = tbq / total * 100
        raw_delta = tbq - tsq
        print(f"\n  ğŸ“¦ SESSION ORDER FLOW (from Exchange Pending Orders):")
        print(f"  Total Buy  Qty : {green(f'{tbq:>15,}')}")
        print(f"  Total Sell Qty : {red(f'{tsq:>15,}')}")
        print(f"  Raw Delta      : {green(f'+{raw_delta:,}') if raw_delta >= 0 else red(f'{raw_delta:,}')}")
        print(f"  Buy Side       : {green(f'{buy_pct:.1f}%') if buy_pct > 55 else (red(f'{buy_pct:.1f}%') if buy_pct < 45 else yellow(f'{buy_pct:.1f}%'))}")

        print(f"\n  ğŸ“Œ LTP â‚¹{ltp:.2f} vs Avg Price â‚¹{avg:.2f}")
        if avg > 0:
            if ltp > avg * 1.002:
                print(f"  {green('âœ… Price above average â€” aggressive buyers lifting the ask (BUY PRESSURE)')}")
            elif ltp < avg * 0.998:
                print(f"  {red('âš ï¸  Price below average â€” aggressive sellers hitting the bid (SELL PRESSURE)')}")
            else:
                print(f"  {yellow('âš¡ Price near average â€” balanced, watching for breakout direction')}")

    # Intraday candle delta (proxy for footprint)
    if df_intraday is not None and len(df_intraday) > 5:
        print(f"\n  ğŸ“ˆ CANDLE DELTA (1-Minute Footprint Proxy):")
        print(dim("  [True footprint needs tick data â€” this is best REST-API approximation]"))

        df = df_intraday.copy()
        df["delta"]    = df.apply(lambda r: r["volume"] if r["close"] >= r["open"] else -r["volume"], axis=1)
        df["cum_delta"] = df["delta"].cumsum()

        # Session segments
        df["hour"] = df["ts"].dt.hour
        open_seg   = df[df["hour"].between(9, 10)]
        mid_seg    = df[df["hour"].between(11, 13)]
        close_seg  = df[df["hour"] >= 14]

        rows = []
        for label, seg in [("Opening (9:15â€“10:30)", open_seg),
                            ("Midday  (11:00â€“13:59)", mid_seg),
                            ("Closing (14:00â€“15:30)", close_seg)]:
            if len(seg) == 0:
                continue
            seg_delta = seg["delta"].sum()
            seg_vol   = seg["volume"].sum()
            bias = green("BUYING") if seg_delta > 0 else red("SELLING")
            rows.append([label, f"{seg_delta:+,}", f"{seg_vol:,}", bias])

        cum_now = df["cum_delta"].iloc[-1]
        tbl(rows, ["Session", "Delta (Volume)", "Total Volume", "Bias"])
        print(f"\n  Cumulative Session Delta: {green(f'+{cum_now:,.0f}') if cum_now >= 0 else red(f'{cum_now:,.0f}')}")
        print(dim("  +ve = net aggressive buying  |  -ve = net aggressive selling"))

    # Hard limits
    print(f"\n  {dim('â”€'*60)}")
    print(dim("  âš ï¸  HARD LIMITS of REST API Order Flow:"))
    print(dim("     â€¢ Cannot see who hit bid vs lifted ask (requires tick-by-tick feed)"))
    print(dim("     â€¢ Cannot see true footprint candles (need Websocket + tick aggregation)"))
    print(dim("     â€¢ For full DOM: subscribe to Upstox WebSocket in FULL_D30 mode"))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  3. INSTITUTIONAL POSITIONING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_institutional_positioning(df_daily, quote, sym):
    """
    Real FII/DII data is published by NSE at EOD.
    We provide:
    - Block trade proxies (volume spikes)
    - Price-volume divergence (smart money vs retail)
    - Delivery volume interpretation
    - EOD FII/DII where to fetch it
    """
    section("ğŸ¦ [3] INSTITUTIONAL POSITIONING")

    if df_daily is None or not HAS_PANDAS:
        print(red("  âŒ No daily candle data."))
        return

    close  = df_daily["close"]
    volume = df_daily["volume"]
    ltp    = quote.get("last_price") or close.iloc[-1]

    avg_vol_50 = volume.tail(50).mean()
    avg_vol_20 = volume.tail(20).mean()

    print(f"\n  ğŸ“Š BLOCK TRADE DETECTION (Volume Spike Analysis):")
    rows = []

    # Last 20 days â€” flag anomalies
    recent = df_daily.tail(20).copy()
    recent["vol_ratio"] = recent["volume"] / avg_vol_50
    recent["direction"] = recent.apply(lambda r: "â–² UP" if r["close"] >= r["open"] else "â–¼ DOWN", axis=1)

    spike_days = recent[recent["vol_ratio"] >= 2.0]
    if len(spike_days) > 0:
        print(f"  {green(f'Found {len(spike_days)} high-volume days (â‰¥2x avg) in last 20 sessions:')}")
        for _, row in spike_days.iterrows():
            dir_col = green(row["direction"]) if "UP" in row["direction"] else red(row["direction"])
            label = green("ACCUMULATION") if "UP" in row["direction"] else red("DISTRIBUTION")
            rows.append([
                str(row["ts"].date()),
                f"â‚¹{row['close']:.2f}",
                f"{row['volume']:,.0f}",
                f"{row['vol_ratio']:.1f}x",
                dir_col,
                label
            ])
        tbl(rows, ["Date", "Close", "Volume", "vs Avg", "Direction", "Inst. Activity"])
    else:
        print(f"  {yellow('No major block activity in last 20 days â€” institutions quiet')}")

    # Price-Volume Divergence
    print(f"\n  ğŸ“‰ PRICE-VOLUME DIVERGENCE (Smart Money vs Retail):")
    pv_rows = []
    # Rising price + falling volume = distribution (smart money selling into retail buying)
    last5_price = close.tail(5).mean()
    prev5_price = close.iloc[-10:-5].mean()
    last5_vol   = volume.tail(5).mean()
    prev5_vol   = volume.iloc[-10:-5].mean()

    price_up  = last5_price > prev5_price
    vol_up    = last5_vol   > prev5_vol

    if price_up and vol_up:
        pv_rows.append([green("Price â–² + Volume â–²"), green("CONFIRMED RALLY"),     "Institutions supporting the move â€” safe to follow"])
    elif price_up and not vol_up:
        pv_rows.append([yellow("Price â–² + Volume â–¼"), yellow("DISTRIBUTION RISK"), "Price rising on low vol â€” smart money selling to retail"])
    elif not price_up and vol_up:
        pv_rows.append([red("Price â–¼ + Volume â–²"), red("PANIC / CAPITULATION"),   "High-vol drop â€” could be final flush before reversal"])
    else:
        pv_rows.append([dim("Price â–¼ + Volume â–¼"), dim("LACK OF INTEREST"),        "Low conviction â€” institutions not participating"])

    tbl(pv_rows, ["Pattern", "Interpretation", "Action"])

    # Delivery volume note
    print(f"\n  ğŸ“¦ DELIVERY VOLUME (FII/DII Proxy):")
    print(f"  {dim('Upstox does not expose delivery % directly via API.')}")
    print(f"  {bold('â¤  Get real FII/DII flows from:')} ")
    print(f"  {cyan('  â€¢ NSE Bhav copy (EOD)  : https://www.nseindia.com/market-data/bulk-deals-block-deals')}")
    print(f"  {cyan('  â€¢ BSE bulk deals        : https://www.bseindia.com/markets/equity/EQReports/bulk-deals.aspx')}")
    print(f"  {cyan('  â€¢ NSE FII/DII daily     : https://www.nseindia.com/market-data/institutional-trading')}")
    print(f"  {cyan('  â€¢ SEBI block trade data : https://www.sebi.gov.in')}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  4 & 7. TIME-BASED INSTITUTIONAL BEHAVIOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_time_behavior(df_intraday):
    """
    Institutions behave very differently by session.
    We show per-session volume/delta breakdown.
    """
    section("â° [4 & 7] TIME-BASED INSTITUTIONAL BEHAVIOR")

    now = datetime.now()
    ist_hour   = now.hour
    ist_minute = now.minute

    # Session classification
    print(f"\n  ğŸ• Current Time: {now.strftime('%H:%M:%S IST')}")
    print()

    sessions = [
        ("9:15 â€“ 10:30",  "AGGRESSIVE OPEN",   "FII/algo algos fire â€” highest volatility, reversals common"),
        ("10:30 â€“ 11:30", "DISCOVERY",          "True direction being established â€” watch volume confirmation"),
        ("11:30 â€“ 13:00", "MIDDAY DRIFT",       "Low liquidity, choppy â€” institutions passive, avoid noise"),
        ("13:00 â€“ 14:00", "PRE-CLOSE SETUP",    "Smart money repositioning before closing â€” watch for unusual vol"),
        ("14:00 â€“ 15:00", "INSTITUTIONAL PUSH", "FII/mutual fund orders flow in â€” trend often accelerates"),
        ("15:00 â€“ 15:30", "CLOSING AUCTION",    "Portfolio rebalancing, closing mark â€” reversals common"),
    ]

    rows = []
    for time_range, label, note in sessions:
        start_h = int(time_range.split(":")[0])
        start_m = int(time_range.split(":")[1].split("â€“")[0].strip())
        if ist_hour == start_h and ist_minute >= start_m:
            active = bold(green("â—€ YOU ARE HERE"))
        elif ist_hour > start_h:
            active = dim("âœ“ PASSED")
        else:
            active = dim("â³ UPCOMING")
        rows.append([time_range, bold(label), note, active])

    tbl(rows, ["Session", "Mode", "Institutional Behavior", "Status"])

    # Per-session analysis from intraday candles
    if df_intraday is not None and len(df_intraday) > 5:
        print(f"\n  ğŸ“Š TODAY'S SESSION BREAKDOWN:")
        df = df_intraday.copy()
        df["hour"] = df["ts"].dt.hour

        seg_rows = []
        for label, h_start, h_end in [
            ("Open (9â€“10)", 9, 10),
            ("Mid (11â€“13)", 11, 13),
            ("Close (14â€“15)", 14, 15),
        ]:
            seg = df[df["hour"].between(h_start, h_end)]
            if len(seg) == 0:
                seg_rows.append([label, "-", "-", "-", dim("No data yet")])
                continue
            vol   = seg["volume"].sum()
            delta = seg.apply(lambda r: r["volume"] if r["close"] >= r["open"] else -r["volume"], axis=1).sum()
            hi    = seg["high"].max()
            lo    = seg["low"].min()
            bias  = green("BUYING") if delta > 0 else red("SELLING")
            seg_rows.append([label, f"{vol:,.0f}", f"{delta:+,.0f}", f"â‚¹{lo:.2f}â€“â‚¹{hi:.2f}", bias])

        tbl(seg_rows, ["Session", "Volume", "Net Delta", "Range", "Bias"])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  5. LIQUIDITY ENGINEERING â€” STOP HUNTS & TRAP ZONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_liquidity_zones(df_daily, df_intraday, ltp):
    """
    Institutions engineer liquidity:
    - Push to equal highs â†’ trigger retail stop losses above
    - Grab liquidity â†’ reverse sharply
    We detect: equal highs/lows, breakout traps, stop hunt zones
    """
    section("ğŸ¯ [5] LIQUIDITY ENGINEERING â€” STOP HUNTS & TRAP ZONES")

    if df_daily is None or not HAS_PANDAS:
        return

    highs = df_daily["high"].tail(30).values
    lows  = df_daily["low"].tail(30).values
    dates = df_daily["ts"].tail(30).values

    EQUAL_THRESHOLD = 0.003  # 0.3% = "equal" high/low

    # Find equal highs (where retail stops cluster)
    eq_highs = []
    for i in range(len(highs) - 1):
        for j in range(i + 1, len(highs)):
            if abs(highs[i] - highs[j]) / highs[i] < EQUAL_THRESHOLD:
                eq_highs.append(highs[j])

    eq_lows = []
    for i in range(len(lows) - 1):
        for j in range(i + 1, len(lows)):
            if abs(lows[i] - lows[j]) / lows[i] < EQUAL_THRESHOLD:
                eq_lows.append(lows[j])

    recent_high = df_daily["high"].tail(5).max()
    recent_low  = df_daily["low"].tail(5).min()
    swing_high  = df_daily["high"].tail(20).max()
    swing_low   = df_daily["low"].tail(20).min()

    print(f"\n  ğŸ“Œ LIQUIDITY POOL MAP:")
    rows = []

    # Above market â€” buy stops (where shorts stop out = fuel for push higher)
    rows.append([magenta("ABOVE MARKET (Buy Stops)"), "", ""])
    rows.append(["Equal Highs Zone", f"â‚¹{max(eq_highs):.2f}" if eq_highs else "None found",
                 "Retail stops clustered here â€” institutions may sweep then reverse"])
    rows.append(["20D Swing High", f"â‚¹{swing_high:.2f}",
                 "Key resistance â€” breakout above = stop hunt or real breakout?"])
    rows.append(["Recent 5D High", f"â‚¹{recent_high:.2f}",
                 "Short-term stop cluster â€” watch for false breakout"])

    rows.append(["", "", ""])
    rows.append([f"{'â”€'*20} LTP â‚¹{ltp:.2f} {'â”€'*20}", "", ""])
    rows.append(["", "", ""])

    # Below market â€” sell stops (where longs stop out = fuel for push lower)
    rows.append([magenta("BELOW MARKET (Sell Stops)"), "", ""])
    rows.append(["Recent 5D Low", f"â‚¹{recent_low:.2f}",
                 "Long stop cluster â€” institutions may sweep for liquidity"])
    rows.append(["20D Swing Low", f"â‚¹{swing_low:.2f}",
                 "Major support â€” break below = stop hunt or true breakdown?"])
    rows.append(["Equal Lows Zone", f"â‚¹{min(eq_lows):.2f}" if eq_lows else "None found",
                 "High-probability buy zone if swept and reclaimed"])

    tbl(rows, ["Zone", "Price Level", "Institutional Interpretation"])

    # Trap detection
    print(f"\n  ğŸª¤ BREAKOUT TRAP DETECTION:")
    trap_rows = []

    # If price recently broke above swing high but closed back below
    last_close = df_daily["close"].iloc[-1]
    last_high  = df_daily["high"].iloc[-1]
    if last_high > swing_high * 0.998 and last_close < swing_high:
        trap_rows.append([red("âš ï¸  BULL TRAP DETECTED"),
                          f"Price pierced â‚¹{swing_high:.2f} but closed below",
                          "Classic stop hunt â€” institutions grabbed stops, may reverse down"])
    elif df_daily["low"].iloc[-1] < swing_low * 1.002 and last_close > swing_low:
        trap_rows.append([green("âœ… BEAR TRAP DETECTED"),
                          f"Price pierced â‚¹{swing_low:.2f} but closed above",
                          "Liquidity grab below â€” institutions may drive price up now"])
    else:
        trap_rows.append([yellow("ğŸŸ¡ NO TRAP NOW"),
                          "No recent sweep/rejection",
                          "Watch equal highs/lows for next sweep"])

    tbl(trap_rows, ["Pattern", "Evidence", "Implication"])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  6. OPTIONS POSITIONING â€” MAX PAIN, PCR, GAMMA ZONES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_options(token, sym, ltp):
    """
    Options OI data tells you where institutions have positioned.
    - Max Pain = price where most options expire worthless
    - PCR = Put/Call ratio â€” market sentiment
    - Heavy Call OI = resistance zone
    - Heavy Put OI = support zone
    - Gamma squeeze zones = forced hedging at key strikes
    Uses NIFTY index chain as macro context for all stocks.
    """
    section("ğŸ“Š [6] OPTIONS POSITIONING â€” MAX PAIN, PCR & GAMMA ZONES")
    print(dim("  [Using NIFTY index option chain as macro context]"))
    print(dim("  [Individual stock F&O available for: MARUTI, ULTRACEMCO, DIVISLAB]"))

    # Get next expiry
    expiries = fetch_option_expiries(token, NIFTY_KEY)
    if not expiries:
        print(red("  âŒ Could not fetch expiry dates."))
        return

    nearest_expiry = expiries[0]
    print(f"\n  ğŸ“… Analyzing expiry: {bold(cyan(nearest_expiry))}")

    chain = fetch_option_chain(token, NIFTY_KEY, nearest_expiry)
    if not chain:
        print(red("  âŒ Option chain data unavailable."))
        return

    if not HAS_PANDAS:
        print(red("  âŒ pandas required for options analysis."))
        return

    df_opt = pd.DataFrame([{
        "strike":      c.get("strike_price", 0),
        "call_oi":     c.get("call_options", {}).get("market_data", {}).get("oi", 0),
        "put_oi":      c.get("put_options",  {}).get("market_data", {}).get("oi", 0),
        "call_vol":    c.get("call_options", {}).get("market_data", {}).get("volume", 0),
        "put_vol":     c.get("put_options",  {}).get("market_data", {}).get("volume", 0),
        "call_iv":     c.get("call_options", {}).get("option_greeks", {}).get("iv", 0),
        "put_iv":      c.get("put_options",  {}).get("option_greeks", {}).get("iv", 0),
        "call_delta":  c.get("call_options", {}).get("option_greeks", {}).get("delta", 0),
        "put_delta":   c.get("put_options",  {}).get("option_greeks", {}).get("delta", 0),
        "call_gamma":  c.get("call_options", {}).get("option_greeks", {}).get("gamma", 0),
        "put_gamma":   c.get("put_options",  {}).get("option_greeks", {}).get("gamma", 0),
        "pcr":         c.get("pcr", 0),
        "underlying":  c.get("underlying_spot_price", 0),
    } for c in chain])

    if df_opt.empty:
        print(red("  âŒ Empty option chain."))
        return

    spot = df_opt["underlying"].iloc[0] if df_opt["underlying"].iloc[0] > 0 else ltp

    # â”€â”€ Max Pain â”€â”€
    # Max pain = strike where total OI pain (loss to option buyers) is maximum
    max_pain_pain = {}
    strikes = sorted(df_opt["strike"].unique())
    for test_strike in strikes:
        call_pain = df_opt[df_opt["strike"] < test_strike]["call_oi"].sum() * \
                    df_opt[df_opt["strike"] < test_strike].apply(
                        lambda r: test_strike - r["strike"], axis=1).mean() if any(df_opt["strike"] < test_strike) else 0
        put_pain = df_opt[df_opt["strike"] > test_strike]["put_oi"].sum() * \
                   df_opt[df_opt["strike"] > test_strike].apply(
                       lambda r: r["strike"] - test_strike, axis=1).mean() if any(df_opt["strike"] > test_strike) else 0
        max_pain_pain[test_strike] = (call_pain or 0) + (put_pain or 0)

    max_pain_strike = min(max_pain_pain, key=max_pain_pain.get) if max_pain_pain else None

    # â”€â”€ PCR â”€â”€
    total_put_oi  = df_opt["put_oi"].sum()
    total_call_oi = df_opt["call_oi"].sum()
    pcr = total_put_oi / total_call_oi if total_call_oi > 0 else 0

    # â”€â”€ Key OI Walls â”€â”€
    top_call_strikes = df_opt.nlargest(3, "call_oi")[["strike", "call_oi"]]
    top_put_strikes  = df_opt.nlargest(3, "put_oi")[["strike", "put_oi"]]

    # â”€â”€ Gamma Concentration â”€â”€
    atm_strikes = df_opt[abs(df_opt["strike"] - spot) < spot * 0.03]
    gamma_exp   = (atm_strikes["call_gamma"] * atm_strikes["call_oi"] +
                   atm_strikes["put_gamma"]  * atm_strikes["put_oi"]).sum()

    print(f"\n  {'â”€'*60}")
    print(f"  NIFTY SPOT          : {bold(f'â‚¹{spot:,.2f}')}")
    print(f"  {'â”€'*60}")
    if max_pain_strike:
        gap_pct = ((spot - max_pain_strike) / spot) * 100
        mp_signal = green(f"Spot {abs(gap_pct):.1f}% ABOVE â€” may drift down to max pain") if gap_pct > 0 \
                    else red(f"Spot {abs(gap_pct):.1f}% BELOW â€” may drift up to max pain")
        print(f"  MAX PAIN STRIKE     : {bold(magenta(f'â‚¹{max_pain_strike:,}'))}  â†’  {mp_signal}")
    print(f"  PUT/CALL RATIO (PCR): {bold(f'{pcr:.2f}')}", end="  ")
    if pcr > 1.3:
        print(green("â†’ OVERSOLD / BULLISH CONTRARIAN (heavy puts = market floor near)"))
    elif pcr < 0.7:
        print(red("â†’ OVERBOUGHT / BEARISH CONTRARIAN (heavy calls = market ceiling near)"))
    else:
        print(yellow("â†’ NEUTRAL (balanced put/call positioning)"))
    print(f"  GAMMA EXPOSURE (ATM): {bold(f'{gamma_exp:.2f}')}", end="  ")
    if gamma_exp > 0:
        print(magenta("â†’ Positive gamma â€” MMs hedge by BUYING dips (stabilizing force)"))
    else:
        print(red("â†’ Negative gamma â€” MMs hedge by SELLING dips (destabilizing force)"))
    print(f"  {'â”€'*60}")

    # Resistance/Support from OI
    print(f"\n  ğŸ”´ CALL OI WALLS (Resistance / Institutional Sell Zones):")
    call_rows = [[f"â‚¹{int(r['strike']):,}", f"{int(r['call_oi']):,}",
                  "STRONG RESISTANCE" if i == 0 else "Resistance"] for i, (_, r) in enumerate(top_call_strikes.iterrows())]
    tbl(call_rows, ["Strike", "Call OI", "Interpretation"])

    print(f"\n  ğŸŸ¢ PUT OI WALLS (Support / Institutional Buy Zones):")
    put_rows  = [[f"â‚¹{int(r['strike']):,}", f"{int(r['put_oi']):,}",
                  "STRONG SUPPORT" if i == 0 else "Support"] for i, (_, r) in enumerate(top_put_strikes.iterrows())]
    tbl(put_rows, ["Strike", "Put OI", "Interpretation"])

    print(f"\n  {dim('How to read this for your stock (' + sym + '):')}")
    print(dim(f"  If NIFTY is near max pain, expect muted range. If far from max pain,"))
    print(dim(f"  directional conviction is real. OI walls act as S/R for index-linked stocks."))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  8. PSYCHOLOGY GAUGE â€” FEAR, GREED, FOMO, TRAP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_psychology(df_daily, quote):
    """
    Market psychology from price action patterns.
    Detects: Panic, Euphoria, FOMO, Trap Mindset.
    """
    section("ğŸ§  [8] MARKET PSYCHOLOGY GAUGE")

    if df_daily is None or not HAS_PANDAS:
        return

    close  = df_daily["close"]
    volume = df_daily["volume"]
    high   = df_daily["high"]
    low    = df_daily["low"]
    ltp    = quote.get("last_price") or close.iloc[-1]

    # â”€â”€ Volatility (ATR) â†’ Fear gauge â”€â”€
    atr = (high - low).tail(14).mean()
    atr_pct = (atr / ltp) * 100

    # â”€â”€ Return metrics â”€â”€
    ret_1d  = ((close.iloc[-1] - close.iloc[-2]) / close.iloc[-2]) * 100
    ret_5d  = ((close.iloc[-1] - close.iloc[-5]) / close.iloc[-5]) * 100
    ret_20d = ((close.iloc[-1] - close.iloc[-20]) / close.iloc[-20]) * 100

    # â”€â”€ Volume trend â”€â”€
    vol_ratio = volume.tail(5).mean() / volume.tail(20).mean()

    # â”€â”€ Psychology scoring â”€â”€
    print(f"\n  ğŸ“ SENTIMENT METRICS:")
    metrics = [
        ["ATR % (Volatility)",  f"{atr_pct:.2f}%",
         red("HIGH FEAR") if atr_pct > 3 else (green("CALM") if atr_pct < 1.5 else yellow("MODERATE"))],
        ["1-Day Return",        f"{ret_1d:+.2f}%",
         green("UP DAY")  if ret_1d > 1 else (red("DOWN DAY") if ret_1d < -1 else yellow("FLAT"))],
        ["5-Day Return",        f"{ret_5d:+.2f}%",
         green("SHORT BULL") if ret_5d > 5 else (red("SHORT BEAR") if ret_5d < -5 else yellow("RANGE"))],
        ["20-Day Return",       f"{ret_20d:+.2f}%",
         green("MEDIUM BULL") if ret_20d > 10 else (red("MEDIUM BEAR") if ret_20d < -10 else yellow("NEUTRAL"))],
        ["Volume vs 20D Avg",   f"{vol_ratio:.2f}x",
         green("HIGH PARTICIPATION") if vol_ratio > 1.3 else (dim("LOW PARTICIPATION") if vol_ratio < 0.7 else yellow("NORMAL"))],
    ]
    tbl(metrics, ["Metric", "Value", "Psychology Signal"])

    # â”€â”€ Pattern Detection â”€â”€
    print(f"\n  ğŸ­ BEHAVIORAL PATTERN DETECTION:")
    patterns = []

    # FOMO: fast rise + high volume + RSI extreme
    if ret_5d > 8 and vol_ratio > 1.5:
        patterns.append([red("âš ï¸  FOMO"), "Fast 5D rise on high vol",
                         "Retail FOMO buying â€” smart money may distribute into strength"])
    # Panic: fast drop + high volume
    if ret_5d < -8 and vol_ratio > 1.5:
        patterns.append([green("ğŸ”” PANIC SELL"), "Fast 5D drop on high vol",
                         "Retail panic â€” potential institutional accumulation zone"])
    # Euphoria: extended run + vol dropping (topping)
    if ret_20d > 20 and vol_ratio < 0.9:
        patterns.append([red("âš ï¸  EUPHORIA/TOP"), "Strong 20D rally, vol declining",
                         "Smart money distributing â€” retail buying, institutions selling"])
    # Capitulation: extended fall + vol spike
    if ret_20d < -20 and vol_ratio > 1.5:
        patterns.append([green("ğŸ”” CAPITULATION"), "Major 20D fall + vol spike",
                         "Final seller exhaustion â€” institutional accumulation likely"])
    # Trap: recent up day but weak close
    last = df_daily.iloc[-1]
    if last["close"] < last["open"] and last["high"] > last["open"] * 1.005:
        patterns.append([red("ğŸª¤ BULL TRAP"),
                         f"High â‚¹{last['high']:.2f} â†’ Close â‚¹{last['close']:.2f}",
                         "Price rejected from highs â€” institutions sold into spike"])
    if last["close"] > last["open"] and last["low"] < last["open"] * 0.995:
        patterns.append([green("ğŸª¤ BEAR TRAP"),
                         f"Low â‚¹{last['low']:.2f} â†’ Close â‚¹{last['close']:.2f}",
                         "Price recovered from lows â€” institutions bought the dip"])

    if not patterns:
        patterns.append([yellow("ğŸŸ¡ NO CLEAR PATTERN"), "Neutral conditions", "No extreme psychological state detected"])

    tbl(patterns, ["Pattern", "Evidence", "Interpretation"])

    # â”€â”€ Macro warnings â”€â”€
    print(f"\n  ğŸ“¡ [4] MACRO CONTEXT (Indicators Cannot Know This):")
    print(f"  {dim('â”€'*60)}")
    print(f"  {bold('Monitor these external factors that override all signals:')}")
    macro_items = [
        ("RBI Policy Meetings",      "MPC meets 6x/year â€” rate changes affect all bank/NBFC stocks"),
        ("US Fed & CPI Data",        "Global risk-on/off â€” FII flows react before Indian markets"),
        ("India VIX",                "VIX >15 = fear, buy puts / hedge. VIX <12 = complacency, watch for spike"),
        ("Earnings Dates",           f"{bold('CHECK')} {bold(cyan('NSE calendar'))} â€” gaps happen overnight"),
        ("Geopolitical Events",      "Sudden reversals from news that no indicator will show"),
        ("INR/USD Rate",             "Rupee depreciation = FII outflow pressure on equities"),
        ("Nifty P/E & FII DII EOD",  "Check https://www.nseindia.com/market-data/institutional-trading daily"),
    ]
    for topic, note in macro_items:
        print(f"  {magenta('â–º')} {bold(topic):<30} {dim(note)}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MASTER INSTITUTIONAL VIEW â€” SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_master_view(sym, ltp, score_dict: dict):
    section("ğŸ§© MASTER INSTITUTIONAL VIEW â€” ALL 8 DIMENSIONS")
    print(f"\n  Stock: {bold(cyan(sym))}  |  LTP: {bold(f'â‚¹{ltp:,.2f}')}")
    print(f"\n  {'Dimension':<35} {'Signal':<20} {'Confidence'}")
    print(f"  {'â”€'*65}")
    for dim_name, (signal, confidence, note) in score_dict.items():
        print(f"  {dim_name:<35} {signal:<30} {confidence}  {dim(note)}")
    print()
    print(dim("  âš ï¸  No single dimension gives the full picture."))
    print(dim("  âœ…  Institutions combine ALL of the above simultaneously."))
    print(dim("  ğŸ“š  Your edge = reading multiple dimensions that agree."))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="Institutional Market Intelligence Engine",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python institutional_edge.py
  python institutional_edge.py --stock DIXON --options
        """
    )
    parser.add_argument("--stock", required=False, help=f"Stock symbol.")
    parser.add_argument("--token", default=None, help="Upstox token")
    parser.add_argument("--options", action="store_true", help="Include NIFTY options analysis")
    parser.add_argument("--no-intraday", action="store_true", help="Skip intraday candles")
    args = parser.parse_args()

    # Priority 1: Use hardcoded ACCESS_TOKEN
    token = args.token or ACCESS_TOKEN
    if not token or token == "PASTE_YOUR_UPSTOX_TOKEN_HERE":
        print(red("âŒ ERROR: Set ACCESS_TOKEN at the top of the code or pass --token YOUR_TOKEN"))
        sys.exit(1)

    # Priority 2: Selection Logic
    sym = args.stock.upper() if args.stock else None
    
    if not sym:
        print(f"\n{bold(cyan('ğŸ“‹ YOUR INSTITUTIONAL WATCHLIST:'))}")
        stocks_list = list(WATCHLIST.keys())
        
        # Display list with numbers
        for idx, s in enumerate(stocks_list, 1):
            name_label = f"[{idx}] {s}"
            print(f"  {name_label:<18}", end="" if idx % 4 != 0 else "\n")
        
        choice = input(f"\n\n{yellow('ğŸ‘‰ Enter Number or Stock Symbol: ')}").strip()
        
        # Check if user entered a number
        if choice.isdigit():
            idx_choice = int(choice) - 1
            if 0 <= idx_choice < len(stocks_list):
                sym = stocks_list[idx_choice]
            else:
                print(red(f"âŒ Selection {choice} is out of range."))
                sys.exit(1)
        else:
            sym = choice.upper()

    if sym not in WATCHLIST:
        print(red(f"âŒ '{sym}' not in watchlist. Valid: {', '.join(WATCHLIST.keys())}"))
        sys.exit(1)

    if not HAS_PANDAS:
        print(red("âŒ Install pandas/numpy: pip install pandas numpy"))
        sys.exit(1)

    info = WATCHLIST[sym]

    print(DIVIDER)
    print(bold(f"  ğŸ›ï¸  INSTITUTIONAL EDGE â€” {sym} ({info['name']})"))
    print(bold(f"  {datetime.now().strftime('%d %b %Y  %H:%M:%S IST')}"))
    print(DIVIDER)

    # --- Data Fetching ---
    print(dim("\n  ğŸ“¡ Fetching live quote..."))
    quote = fetch_full_quote(token, info["key"])
    ltp   = quote.get("last_price", 0) or 0

    print(dim("  ğŸ“¡ Fetching daily candles (60 days)..."))
    df_daily = fetch_daily_candles(token, info["key"], days=60)

    df_intraday = None
    if not args.no_intraday:
        print(dim("  ğŸ“¡ Fetching intraday 1-min candles..."))
        df_intraday = fetch_intraday_candles(token, info["key"])
        if df_intraday is not None:
            print(dim(f"  âœ… {len(df_intraday)} intraday candles loaded"))
        else:
            print(dim("  âš ï¸  Intraday data unavailable (use --no-intraday post-market)"))

    # --- Run all 8 analyses (Uses your original 900 lines of logic) ---
    analyze_dom(quote)
    analyze_order_flow(quote, df_intraday)
    analyze_institutional_positioning(df_daily, quote, sym)
    analyze_time_behavior(df_intraday)
    analyze_liquidity_zones(df_daily, df_intraday, ltp or (df_daily["close"].iloc[-1] if df_daily is not None else 0))

    if args.options:
        analyze_options(token, sym, ltp)
    else:
        print(f"\n{dim('  ğŸ’¡ Run with --options flag to include NIFTY options chain analysis')}")

    analyze_psychology(df_daily, quote)

    # Master summary (Using your original summary logic)
    print_master_view(sym, ltp, {
        "1. DOM (Order Book)":        (green("âœ… AVAILABLE"),  "HIGH",   "5-level bid/ask depth"),
        "2. Order Flow Delta":        (yellow("âš¡ PROXY"),      "MEDIUM", "Candle delta + buy/sell qty"),
        "3. Institutional Positioning":(yellow("âš¡ PROXY"),     "MEDIUM", "Volume spike + price-vol divergence"),
        "4. Macro Shocks":            (red("âŒ MANUAL"),        "LOW",    "Monitor RBI/Fed/VIX/news manually"),
        "5. Liquidity Engineering":   (green("âœ… COMPUTED"),    "HIGH",   "Equal highs/lows, trap detection"),
        "6. Options OI & Gamma":      (green("âœ… AVAILABLE") if args.options else yellow("âš¡ USE --options"), "HIGH", "PCR, Max Pain, Gamma zones"),
        "7. Time-Based Behavior":      (green("âœ… COMPUTED"),    "HIGH",   "Session delta from 1-min candles"),
        "8. Psychology Gauge":         (green("âœ… COMPUTED"),    "MEDIUM", "ATR, vol patterns, trap detection"),
    })

    print(f"\n{DIVIDER}")
    print(dim("  âš ï¸  Educational use only. Not financial advice."))
    print(DIVIDER + "\n")
if __name__ == "__main__":
    main()